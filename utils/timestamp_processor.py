# utils/timestamp_processor.py

"""
Timestamp processing utilities for subtitle generation.
Handles duration adjustments, overlap fixing, and timestamp formatting.
"""

from typing import List, Tuple
import numpy as np # type: ignore

try:
    import librosa # type: ignore
    LIBROSA_AVAILABLE = True
except ImportError:
    LIBROSA_AVAILABLE = False


def detect_continuous_vocalization(
    audio_path: str,
    check_time: float,
    lookforward_duration: float = 1.5,
    energy_threshold: float = 0.025,
    log_func = None
) -> Tuple[bool, float]:
    """
    Detects if there's sustained vocalization using RMS energy.
    Kept as a backup for non-speech sounds (screams not caught by Whisper).
    """
    if not LIBROSA_AVAILABLE or not audio_path:
        return False, check_time
    
    try:
        audio, sr = librosa.load(audio_path, sr=16000, offset=check_time, duration=lookforward_duration)
        if len(audio) == 0: return False, check_time
        
        window_size = int(0.05 * sr)
        hop_size = int(0.01 * sr)
        sustained_until = check_time
        is_vocalizing = False
        
        for i in range(0, len(audio) - window_size, hop_size):
            window = audio[i:i + window_size]
            rms_energy = np.sqrt(np.mean(window**2))
            current_time = check_time + (i / sr)
            
            if rms_energy > energy_threshold:
                sustained_until = current_time + (window_size / sr)
                is_vocalizing = True
            elif is_vocalizing:
                break
        
        return is_vocalizing, sustained_until
        
    except Exception:
        return False, check_time


def adjust_word_duration(start_time, end_time, min_duration=0.3, max_duration=1.5):
    """Adjust word timestamps based on duration constraints."""
    current_duration = end_time - start_time
    if current_duration > max_duration:
        return end_time - max_duration, end_time
    elif current_duration < min_duration:
        return start_time, start_time + min_duration
    return start_time, end_time


def apply_duration_adjustments(transcriptions, track_name="", log_func=None):
    """Apply duration adjustments to a list of transcriptions."""
    if not transcriptions or not log_func: return transcriptions
    
    log_func(f"Applying duration adjustments for {track_name}...")
    adjusted_transcriptions = []
    
    for line in transcriptions:
        try:
            time_part, text = line.split(':', 1)
            start_str, end_str = time_part.split('-')
            new_start, new_end = adjust_word_duration(float(start_str), float(end_str))
            adjusted_transcriptions.append(f"{new_start:.2f}-{new_end:.2f}:{text}")
        except (ValueError, IndexError):
            adjusted_transcriptions.append(line)
            
    return adjusted_transcriptions


def fix_overlapping_timestamps(transcriptions, min_duration=0.1):
    """Fix overlapping timestamps in transcriptions."""
    if not transcriptions: return []
    
    parsed = []
    for line in transcriptions:
        try:
            time_part, text = line.split(':', 1)
            start, end = map(float, time_part.split('-'))
            parsed.append((start, end, text.strip()))
        except ValueError: continue
    
    parsed.sort(key=lambda x: x[0])
    fixed = []
    if parsed:
        fixed.append(parsed[0])
        for i in range(1, len(parsed)):
            prev_start, prev_end, prev_text = fixed[-1]
            curr_start, curr_end, curr_text = parsed[i]
            
            if curr_end - curr_start < min_duration:
                curr_end = curr_start + min_duration
            
            if curr_start < prev_end:
                curr_start = prev_end + 0.01
                if curr_end < curr_start + min_duration:
                    curr_end = curr_start + min_duration
            
            fixed.append((curr_start, curr_end, curr_text))
    
    return [f"{s:.2f}-{e:.2f}: {t}" for s, e, t in fixed]


def parse_timestamp_line(line):
    try:
        time_part, text = line.split(':', 1)
        start, end = map(float, time_part.split('-'))
        return start, end, text.strip()
    except (ValueError, IndexError):
        return None

def format_timestamp_line(start_time, end_time, text):
    return f"{start_time:.2f}-{end_time:.2f}: {text}"


def extend_segments_for_dialogue(
    segments_to_keep: List[Tuple[float, float]],
    raw_mic_transcriptions: List[str],
    raw_desktop_transcriptions: List[str],
    log_func,
    max_extension_seconds: float = 3.0,
    buffer_seconds: float = 0.5,
    mic_audio_path: str = None,
    desktop_audio_path: str = None
) -> List[Tuple[float, float]]:
    """
    Extends trim segments to protect dialogue using BOTH Whisper timestamps (Primary) 
    and RMS energy (Secondary/Fallback).
    """
    if not segments_to_keep:
        log_func("   No segments to protect")
        return []
    
    # 1. Parse all words into a searchable list
    all_words = [] 
    for line in raw_mic_transcriptions:
        parsed = parse_timestamp_line(line)
        if parsed: all_words.append(parsed + ("mic",))
    for line in raw_desktop_transcriptions:
        parsed = parse_timestamp_line(line)
        if parsed: all_words.append(parsed + ("desktop",))
    
    all_words.sort(key=lambda x: x[0])
    segments_to_keep.sort(key=lambda x: x[0])
    
    extended_segments = []
    last_end_time = 0.0

    for segment_idx, (ai_start, ai_end) in enumerate(segments_to_keep):
        log_func(f"\n   üìç Processing segment {segment_idx + 1}: {ai_start:.2f}s - {ai_end:.2f}s")
        
        new_start = max(0.0, ai_start - buffer_seconds)
        new_end = ai_end
        
        if new_start < last_end_time:
            new_start = last_end_time

        # --- STEP 1: WHISPER-BASED PROTECTION (The Fix) ---
        # Check if the cut point (ai_end) slices through a word or is uncomfortably close
        extension_found = False
        
        # Look for words that start before the cut but end after it
        # OR words that start within a small window after the cut (don't cut mid-sentence flow)
        sentence_flow_window = 0.5 
        
        for (w_start, w_end, text, track) in all_words:
            # Case A: Cut is inside a word
            if w_start <= ai_end < w_end:
                log_func(f"      üõ°Ô∏è Protected cut word ({track}): '{text}' ({w_start:.2f}-{w_end:.2f})")
                new_end = max(new_end, w_end + buffer_seconds)
                extension_found = True
            
            # Case B: Cut is right before a word (likely mid-sentence)
            elif ai_end <= w_start < (ai_end + sentence_flow_window):
                # Only extend if it doesn't push us too far
                if (w_end - ai_end) < max_extension_seconds:
                    log_func(f"      üõ°Ô∏è Extended for flow ({track}): '{text}' starts at {w_start:.2f}")
                    new_end = max(new_end, w_end + buffer_seconds)
                    extension_found = True

        if extension_found:
            # Cap the extension
            if (new_end - ai_end) > max_extension_seconds:
                new_end = ai_end + max_extension_seconds
                log_func(f"      ‚ö†Ô∏è Extension capped at {new_end:.2f}s")

        # --- STEP 2: ENERGY-BASED PROTECTION (The Backup) ---
        # Only run if Whisper didn't already extend it significantly.
        # This catches screams/laughs that Whisper ignored.
        if (new_end - ai_end) < 0.5 and LIBROSA_AVAILABLE:
            log_func(f"      üé§ Checking for untranscribed vocalization (screams/laughs)...")
            
            mic_active, mic_end = detect_continuous_vocalization(mic_audio_path, new_end, 1.5, 0.025, log_func)
            desk_active, desk_end = detect_continuous_vocalization(desktop_audio_path, new_end, 1.5, 0.025, log_func)
            
            actual_vocal_end = max(mic_end, desk_end)
            if actual_vocal_end > new_end:
                extension = actual_vocal_end - new_end
                if extension <= max_extension_seconds:
                    new_end = actual_vocal_end + buffer_seconds
                    log_func(f"      üîä Extended for vocal energy to {new_end:.2f}s")
                else:
                    new_end = new_end + max_extension_seconds
                    log_func(f"      üîä Energy extends too far, capped.")

        # Default buffer if nothing else happened
        if new_end == ai_end:
            new_end += buffer_seconds

        if new_start < new_end:
            extended_segments.append((new_start, new_end))
            last_end_time = new_end
            log_func(f"      ‚úÖ Final: {new_start:.2f}s - {new_end:.2f}s")

    return extended_segments